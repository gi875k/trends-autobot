import time
import pandas as pd
import gspread
import pytz
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait # ğŸ”´ ì§€ëŠ¥ì ì¸ ëŒ€ê¸°ë¥¼ ìœ„í•´ ì¶”ê°€
from selenium.webdriver.support import expected_conditions as EC # ğŸ”´ ì§€ëŠ¥ì ì¸ ëŒ€ê¸°ë¥¼ ìœ„í•´ ì¶”ê°€
from bs4 import BeautifulSoup
from datetime import datetime
import requests
import json

# --- 1. Google Trends ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
def scrape_google_trends():
    """Seleniumì„ ì‚¬ìš©í•˜ì—¬ Google Trendsì˜ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    # ... (ì´ì „ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ)
    url = "https://trends.google.com/trending?geo=KR&hours=4"
    options = webdriver.ChromeOptions()
    options.add_argument('headless')
    options.add_argument('window-size=1920x1080')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = None
    try:
        print("ğŸ” [Google] Seleniumìœ¼ë¡œ Chrome ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        driver = webdriver.Chrome(service=service, options=options)
        driver.get(url)
        print("   - JavaScript ë°ì´í„° ë¡œë”© ëŒ€ê¸° ì¤‘ (3ì´ˆ)...")
        time.sleep(3)
        html_source = driver.page_source
        print("âœ… [Google] í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ!")
        
        soup = BeautifulSoup(html_source, 'lxml')
        table_body = soup.find('tbody', jsname='cC57zf')
        if not table_body:
            print("âŒ [Google] ê²€ìƒ‰ì–´ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        rows = table_body.find_all('tr')
        if not rows:
            print("âŒ [Google] ê²€ìƒ‰ì–´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        keywords = [row.find('div', class_='mZ3RIc').get_text(strip=True) for row in rows if row.find('div', class_='mZ3RIc')]
        print(f"âœ… [Google] ìŠ¤í¬ë˜í•‘ ì„±ê³µ! ({len(keywords)}ê°œ í‚¤ì›Œë“œ ë°œê²¬)")
        return keywords

    except Exception as e:
        print(f"âŒ [Google] Selenium ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    finally:
        if driver:
            driver.quit()

# --- 2. ZUM íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (2í˜ì´ì§€ ìˆ˜ì§‘ ê¸°ëŠ¥ ìµœì¢… ìˆ˜ì •) ---
def scrape_zum_trends():
    """[ìµœì¢… ìˆ˜ì •] Seleniumìœ¼ë¡œ 'ë”ë³´ê¸°'ë¥¼ í´ë¦­í•˜ê³  1, 2í˜ì´ì§€ í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    url = "https://m.zum.com"
    options = webdriver.ChromeOptions()
    options.add_argument('headless')
    options.add_argument('window-size=1920x1080')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36")

    service = Service(ChromeDriverManager().install())
    driver = None
    try:
        print("ğŸ” [ZUM] 'AI ì´ìŠˆ íŠ¸ë Œë“œ' ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        driver = webdriver.Chrome(service=service, options=options)
        driver.get(url)
        # ì´ˆê¸° ë¡œë”©ì´ ì¶©ë¶„íˆ ë˜ë„ë¡ ëª…ì‹œì ìœ¼ë¡œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.ai-issue-trend"))
        )
        print("   - í˜ì´ì§€ ì´ˆê¸° ë¡œë”© ì™„ë£Œ.")
        
        # --- 1í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ---
        html_source_p1 = driver.page_source
        soup_p1 = BeautifulSoup(html_source_p1, 'lxml')
        container_p1 = soup_p1.select_one('div.ai-issue-trend')
        if not container_p1:
            print("âŒ [ZUM] 'AI ì´ìŠˆ íŠ¸ë Œë“œ' ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        keyword_tags_p1 = container_p1.select('.title-box p.title span')
        keywords_p1 = [tag.get_text(strip=True) for tag in keyword_tags_p1]
        print(f"âœ… [ZUM] 1í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì„±ê³µ! ({len(keywords_p1)}ê°œ)")

        all_keywords = list(keywords_p1)

        # --- 2í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ë¡œì§ ---
        try:
            print("   - 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì‹œë„...")
            # 1. 'ë”ë³´ê¸°' ë²„íŠ¼ì„ ì°¾ì•„ì„œ í´ë¦­í•©ë‹ˆë‹¤.
            more_button = driver.find_element(By.CSS_SELECTOR, 'button.btn-issue-more')
            driver.execute_script("arguments[0].click();", more_button) # JS í´ë¦­ìœ¼ë¡œ ë” í™•ì‹¤í•˜ê²Œ
            
            # 2. í˜ì´ì§€ ë²ˆí˜¸ê°€ '2'ë¡œ ë°”ë€” ë•Œê¹Œì§€ ìµœëŒ€ 5ì´ˆê°„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
            WebDriverWait(driver, 5).until(
                EC.text_to_be_present_in_element((By.CSS_SELECTOR, 'span.current-page'), '2')
            )
            print("   - 2í˜ì´ì§€ ë¡œë”© ì™„ë£Œ.")
            
            # 3. 2í˜ì´ì§€ ë‚´ìš© ìŠ¤í¬ë˜í•‘
            html_source_p2 = driver.page_source
            soup_p2 = BeautifulSoup(html_source_p2, 'lxml')
            container_p2 = soup_p2.select_one('div.ai-issue-trend')
            if container_p2:
                keyword_tags_p2 = container_p2.select('.title-box p.title span')
                keywords_p2 = [tag.get_text(strip=True) for tag in keyword_tags_p2]
                all_keywords.extend(keywords_p2)
                print(f"âœ… [ZUM] 2í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì„±ê³µ! ({len(keywords_p2)}ê°œ)")

        except Exception:
            print("   - 2í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 1í˜ì´ì§€ ê²°ê³¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        final_keywords = list(dict.fromkeys(all_keywords))
        
        if not final_keywords:
            print("âŒ [ZUM] ìµœì¢… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        print(f"âœ… [ZUM] ìµœì¢… ìŠ¤í¬ë˜í•‘ ì„±ê³µ! (ì´ {len(final_keywords)}ê°œ í‚¤ì›Œë“œ ë°œê²¬)")
        return final_keywords

    except Exception as e:
        print(f"âŒ [ZUM] Selenium ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    finally:
        if driver:
            driver.quit()

# --- 3. NATE íŠ¸ë Œë“œ í¬ë¡¤ëŸ¬ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
def scrape_nate_trends():
    """NATEì˜ ì‹¤ì‹œê°„ ì´ìŠˆ í‚¤ì›Œë“œ JSON ë°ì´í„°ë¥¼ ì§ì ‘ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        print("ğŸ” [NATE] ì‹¤ì‹œê°„ ì´ìŠˆ í‚¤ì›Œë“œ API ìš”ì²­ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        now = datetime.now().strftime('%Y%m%d%H%M')
        url = f'https://www.nate.com/js/data/jsonLiveKeywordDataV1.js?v={now}'
        response = requests.get(url)
        response.raise_for_status()
        data = response.content.decode('euc-kr')
        keyword_list = json.loads(data)
        keywords = [item[1] for item in keyword_list]
        print(f"âœ… [NATE] ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ! ({len(keywords)}ê°œ í‚¤ì›Œë“œ ë°œê²¬)")
        return keywords
    except Exception as e:
        print(f"âŒ [NATE] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --- 4. Google Sheet ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
def update_google_sheet(google_data, zum_data, nate_data):
    """3ê°œì˜ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì·¨í•©í•˜ì—¬ Google Sheetì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        print("\nğŸ”„ Google Sheetì— ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
        client = gspread.authorize(creds)
        sheet = client.open("ë¸”ë¡œê·¸ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´").sheet1
        print(f"   - '{sheet.title}' ì‹œíŠ¸ì— ì—°ê²° ì„±ê³µ!")

        sheet.clear()

        kst = pytz.timezone('Asia/Seoul')
        now_kst = datetime.now(kst)
        timestamp_text = now_kst.strftime('(%mì›” %dì¼ %Hì‹œ ì—…ë°ì´íŠ¸)')
        sheet.update_acell('A1', timestamp_text)
        print(f"âœ… ê¸°ì¤€ ì‹œê°„ '{timestamp_text}'ì„(ë¥¼) A1ì…€ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        google_series = pd.Series(google_data, name='Google íŠ¸ë Œë“œ')
        zum_series = pd.Series(zum_data, name='ZUM íŠ¸ë Œë“œ')
        nate_series = pd.Series(nate_data, name='NATE íŠ¸ë Œë“œ')
        
        combined_df = pd.concat([google_series, zum_series, nate_series], axis=1)

        if not combined_df.empty:
            combined_df.fillna('', inplace=True)
            sheet.update('A2', [combined_df.columns.values.tolist()] + combined_df.values.tolist(), value_input_option='USER_ENTERED')
            print("âœ… Google, ZUM, NATE í‚¤ì›Œë“œ ëª©ë¡ì„ A2ì…€ë¶€í„° ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except FileNotFoundError:
        print("âŒ 'credentials.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Google Cloud Consoleì—ì„œ ìƒì„± í›„, ì½”ë“œì™€ ê°™ì€ í´ë”ì— ì €ì¥í•´ì£¼ì„¸ìš”.")
    except gspread.exceptions.SpreadsheetNotFound:
        print("âŒ Google Sheetì—ì„œ 'ë¸”ë¡œê·¸ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´' ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ Google Sheet ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ (ë³€ê²½ ì—†ìŒ) ---
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸš€ Google, ZUM, NATE íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘ ë° ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 50)
    
    google_keywords = scrape_google_trends()
    print("-" * 50)
    zum_keywords = scrape_zum_trends()
    print("-" * 50)
    nate_keywords = scrape_nate_trends()
    
    if google_keywords or zum_keywords or nate_keywords:
        update_google_sheet(google_keywords, zum_keywords, nate_keywords)
    else:
        print("\nëª¨ë“  ì†ŒìŠ¤ì—ì„œ í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•´ Google Sheetë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
